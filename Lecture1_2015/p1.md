

Digital Data Collection - getting started
========================================================
width: 1200
author: Rolf Fredheim and Yulia Shenderovich
date: University of Cambridge
font-family: 'Rockwell'
css:style.css

17/02/2014

Logging on
========================================================
type: s1

Before you sit down:
- Do you have your MCS password?
- Do you have your Raven password?
  - If you answered **'no'** to either then go to the University Computing Services (just outside the door) NOW!
- Are you registered? If not, see me!

Download these slides 
========================================================
type:sq2

Follow link from course description on the SSRMC pages or go directly to 
http://fredheir.github.io/WebScraping/

Download the R file to your computer

Optionally download the slides

And again, optionally open the html slides in your browser



Install the following packages:
===============
knitr
ggplot2
lubridate
plyr
jsonlite
stringr

press **preview** to view the slides in RStudio


Who is this course for
===============
<s>Computer scientists</s>

Anyone with some minimal background in coding and good computer literacy


By the end of the course you will have
==============
Created a system to extract text and numbers from a large number of web pages

Learnt to harvest links

Worked with an API to gather data, e.g. from YouTube

Convert messy data into tabular data


What will we need?
==============
A windows Computer

A modern browser - Chrome or Firefox

<s>~~An up to date version of Rstudio~~</s>


Getting help
============
- ?[functionName]
- StackOverflow
- Ask each other. 


Outline
========================================================
type:section

**Theory**

Practice


What is 'Web Scraping'?
========================================================
From [Wikipedia](http://en.wikipedia.org/wiki/Web_scraping)
> Web scraping (web harvesting or web data extraction) is a computer software technique of extracting information from websites.


When might this be useful? (your examples)

- 
- 
- 
- 

Imposing structure on data
=========
Again, from [Wikipedia](http://en.wikipedia.org/wiki/Web_scraping)
> ... Web scraping focuses on the **transformation of unstructured data** on the web, typically in HTML format, into structured data that can be stored and analyzed in **a central local database or spreadsheet**. 



What will we learn? 
====================
1) working with text in R

2) Connecting R to the outside world

3) Downloading from within R



Example
=======
Approximate number of web pages

<img src="https://github.com/fredheir/WebScraping/blob/master/Lecture1/i2.jpg?raw=true" alt="Drawing" />

Tabulate this data
======


```r
require (ggplot2)
clubs <- c("Tottenham","Arsenal","Liverpool",
           "Everton","ManU","ManC","Chelsea")
nPages <- c(67,113,54,16,108,93,64)
df <- data.frame(clubs,nPages)
df
```

```
      clubs nPages
1 Tottenham     67
2   Arsenal    113
3 Liverpool     54
4   Everton     16
5      ManU    108
6      ManC     93
7   Chelsea     64
```

Visualise it
=======

```r
ggplot(df,aes(clubs,nPages,fill=clubs))+
  geom_bar(stat="identity")+
  coord_flip()+theme_bw(base_size=70)
```

![plot of chunk unnamed-chunk-2](p1-figure/unnamed-chunk-2-1.png) 

Health and Safety
=====================
<p align="center"><img src="http://static2.wikia.nocookie.net/__cb20130318135906/deadfrontier/images/c/cb/Warning.png" alt="Drawing"style="width: 30%;"/></p>

Programming with Humanists: Reflections on Raising an Army of Hacker-Scholars in the Digital Humanities
http://openbookpublishers.com/htmlreader/DHP/chap09.html#ch09


Why might the Google example not be a good one?
=====================

Bandwidth
=================
<p align="center"><img src="http://www.cisco.com/web/about/ac123/ac147/images/ipj/ipj_7-4/dos_figure_4.gif" alt="Drawing" /></p>
***
> the agent machines (slave zombies) begin to send a large volume of packets to the victim, flooding its system with useless load and exhausting its resources.

source: cisco.com

We will not: 
- run parallel processes

we will:
- test code on minimal data

Practice
==============
type:section
- **String manipulation**
- Loops
- Scraping

The JSON data
==================

http://stats.grok.se/json/en/201401/web_scraping

{"daily_views": {"2013-01-12": 542, "2013-01-13": 593, "2013-01-10": 941, "2013-01-11": 798, "2013-01-16": 1119, "2013-01-17": 1124, "2013-01-14": 908, "2013-01-15": 1040, "2013-01-30": 1367, "2013-01-18": 1027, "2013-01-19": 743, "2013-01-31": 1151, "2013-01-29": 1210, "2013-01-28": 1130, "2013-01-23": 1275, "2013-01-22": 1131, "2013-01-21": 1008, "2013-01-20": 707, "2013-01-27": 789, "2013-01-26": 747, "2013-01-25": 1073, "2013-01-24": 1204, "2013-01-01": 379, "2013-01-03": 851, "2013-01-02": 807, "2013-01-05": 511, "2013-01-04": 818, "2013-01-07": 745, "2013-01-06": 469, "2013-01-09": 946, "2013-01-08": 912}, "project": "en", "month": "201301", "rank": -1, "title": "web_scraping"}




String manipulation in R
==============
type:sq2

Top string manipulation functions:
<small>
- tolower (also  toupper, capitalize)
- grep
- gsub
- str_split (library: stringr)
-substring
- paste and paste0
- nchar
- str_trim (library: stringr)
</small>

Reading: 
<small>
- http://en.wikibooks.org/wiki/R_Programming/Text_Processing
- http://chemicalstatistician.wordpress.com/2014/02/27/useful-functions-in-r-for-manipulating-text-data/
- http://gastonsanchez.com/blog/resources/how-to/2013/09/22/Handling-and-Processing-Strings-in-R.html
</small>


Changing the case
================
incremental:true
We can apply them to individual strings, or to vectors:

```r
tolower('ROLF')
```

```
[1] "rolf"
```

```r
states = rownames(USArrests)
tolower(states[0:4])
```

```
[1] "alabama"  "alaska"   "arizona"  "arkansas"
```

```r
toupper(states[0:4])
```

```
[1] "ALABAMA"  "ALASKA"   "ARIZONA"  "ARKANSAS"
```

Number of characters
================
incremental:true
We can also use this to make selections:

```r
nchar(states)
```

```
 [1]  7  6  7  8 10  8 11  8  7  7  6  5  8  7  4  6  8  9  5  8 13  8  9
[24] 11  8  7  8  6 13 10 10  8 14 12  4  8  6 12 12 14 12  9  5  4  7  8
[47] 10 13  9  7
```

```r
states[nchar(states)==5]
```

```
[1] "Idaho" "Maine" "Texas"
```


Cutting strings
============
We can use fixed positions, e.g. to get first character
m

or to get a fixed part of the string:
text

Can you see how this function works? If not use ?substring


str_split
==============
incremental:true
type:sq

- Manipulating URLs
- Editing time stamps, etc

- syntax: str_split(inputString,pattern)
returns a list

```r
require(stringr)
link="http://stats.grok.se/json/en/201401/web_scraping"
str_split(link,'/')
```

```
[[1]]
[1] "http:"         ""              "stats.grok.se" "json"         
[5] "en"            "201401"        "web_scraping" 
```

```r
unlist(str_split(link,"/"))
```

```
[1] "http:"         ""              "stats.grok.se" "json"         
[5] "en"            "201401"        "web_scraping" 
```

Cleaning data
============
type:sq1
incremental:true

- nchar
- tolower (also  toupper)
- str_trim (library: stringr)

```r
annoyingString <- "\n    something HERE  \t\t\t"
```
***

```r
nchar(annoyingString)
```

```
[1] 24
```

```r
str_trim(annoyingString)
```

```
[1] "something HERE"
```

```r
tolower(str_trim(annoyingString))
```

```
[1] "something here"
```

```r
nchar(str_trim(annoyingString))
```

```
[1] 14
```


Structured practice
===========
type:alert
Remember how to read in files using R? Load in some text from the web:
<small>

























































```
Error in file(con, "r") : cannot open the connection
```
